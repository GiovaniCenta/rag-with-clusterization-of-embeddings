{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 301M/301M [01:52<00:00, 2.67MB/s] \n",
      "Downloading data: 100%|██████████| 31.1M/31.1M [00:12<00:00, 2.52MB/s]\n",
      "Downloading data: 100%|██████████| 28.1M/28.1M [00:10<00:00, 2.65MB/s]\n",
      "Downloading data: 100%|██████████| 27.6M/27.6M [00:10<00:00, 2.66MB/s]\n",
      "Generating train split: 100%|██████████| 90447/90447 [00:01<00:00, 64899.64 examples/s]\n",
      "Generating validation split: 100%|██████████| 7405/7405 [00:00<00:00, 67684.56 examples/s]\n",
      "Generating test split: 100%|██████████| 7405/7405 [00:00<00:00, 68748.73 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"hotpot_qa\",\"fullwiki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = dataset['train']\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# Extrair texto do contexto\n",
    "df['chunk_text'] = df['context'].apply(lambda x: ' '.join([' '.join(sent) for sent in x['sentences']]))\n",
    "\n",
    "# Extrair o primeiro título para simplificar, ajuste conforme necessário\n",
    "df['document_name'] = df['context'].apply(lambda x: x['title'][0])\n",
    "\n",
    "# Reorganizar e renomear colunas\n",
    "df = df[['chunk_text', 'question', 'document_name', 'answer']]\n",
    "df.columns = ['chunk_text', 'query', 'document_name', 'answer']\n",
    "\n",
    "# Adicionar colunas vazias\n",
    "df['embedding'] = ''\n",
    "df['cluster_label'] = ''\n",
    "df['pca_components'] = ''\n",
    "\n",
    "# Selecionar as primeiras 1000 linhas\n",
    "df = df.head(1000)\n",
    "\n",
    "# Salvar o DataFrame modificado como arquivo pickle\n",
    "df.to_pickle('hotpot_qa_modificado_1000rows.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['chunk_text', 'query', 'document_name', 'answer', 'embedding',\n",
      "       'cluster_label', 'pca_components'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_utils import *\n",
    "import pandas as pd\n",
    "df = pd.read_pickle('hotpot_qa_modificado_1000rows.pkl')\n",
    "df['embedding'] = df['chunk_text'].apply(lambda x: embed_with_openai(x))\n",
    "df.to_pickle('hotpot_qa_modificado_1000rows_embedded.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
